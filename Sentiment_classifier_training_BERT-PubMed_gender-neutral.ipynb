{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "512de335-019b-4e3b-88b4-506114eea7b2",
   "metadata": {},
   "source": [
    "### Gender-Neutral Sentiment Classifier based on BERT-PubMed \n",
    "\n",
    "\n",
    "Portions of this code are Copyright 2020 by the TensorFlow Hub Authors and are used in accordance with the Apache 2.0 License\n",
    "\n",
    "Otherwise Copyright (C) 2023 by the Regents of the University of California and licensed under the Apache License, Version 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c3b3fa0-a840-458d-8e1c-c56ffb6f83eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310acd9-f41f-4dd3-8e05-ab6e610a3056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prerequisite TensorFlow libraries\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "946bb7f3-4144-407b-b407-f3ab7249777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to remove gendered pronouns and nouns from the training dataset\n",
    "\n",
    "pronouns_gendered = ['himself', 'herself', 'him', 'her', 'he', 'she', 'his', 'hers', 'he\\'s', 'she\\'s', \n",
    "                     'guys', 'gals', 'man', 'woman', 'guy', 'gal', 'men', 'women']\n",
    "pronouns_nongendered = ['themself', 'themself', 'them', 'them', 'they', 'they', 'their', 'their', 'they\\'re', 'they\\'re', \n",
    "                        'people', 'people', 'person', 'person', 'person', 'person', 'people', 'people']\n",
    "\n",
    "def remove_gender(b_sentence):\n",
    "    new_sentence = ''\n",
    "    sentence = str(b_sentence,'utf-8')\n",
    "    #print(len(sentence))\n",
    "    #print(sentence)\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in pronouns_gendered:\n",
    "            new_sentence += pronouns_nongendered[pronouns_gendered.index(word.lower())] + ' '\n",
    "        elif word.rstrip('.').lower() in pronouns_gendered:\n",
    "            new_sentence += pronouns_nongendered[pronouns_gendered.index(word.rstrip('.').lower())] + '. '\n",
    "        else:\n",
    "            new_sentence += word + ' '\n",
    "    return bytes(new_sentence,'utf-8')\n",
    "\n",
    "def rg_array(sentence_array):\n",
    "    rgv = np.vectorize(remove_gender)\n",
    "    return rgv(sentence_array)\n",
    "\n",
    "def rg_tensor(t_string, label):\n",
    "    [t_string,] = tf.py_function(rg_array, [t_string], [tf.string])\n",
    "    return t_string, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d310a39-6613-4c6e-8fc7-5cde8882210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the LMRD/IMDB training data\n",
    "# Uncomment and run the below if not already downloaded \n",
    "# url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "#dataset = tf.keras.utils.get_file('aclImdb_v1.tar.gz', url, untar=True, cache_dir='.', cache_subdir='')\n",
    "#dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "#train_dir = os.path.join(dataset_dir, 'train')\n",
    "#remove_dir = os.path.join(train_dir, 'unsup') shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c90433-e2ee-44b9-8e50-a6970daa9c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Load and process the training and validation datasets\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "# Load training dataset\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "class_names = raw_train_ds.class_names\n",
    "\n",
    "# Remove gendered pronouns from training dataset\n",
    "raw_train_ds = raw_train_ds.map(rg_tensor)\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Load validation datset\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)\n",
    "\n",
    "# Remove gendered pronouns from validation dataset\n",
    "val_ds = val_ds.map(rg_tensor)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ff2c7f-36c2-408a-87a0-48ff4a0ad0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "# Load BERT-Pubmed from TensorFlow Hub\n",
    "\n",
    "bert_model_name = 'experts_pubmed'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf5aaa2-a7b6-45cf-9f9f-3835e96e8d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_word_ids', 'input_type_ids', 'input_mask']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# define BERT preprocessing model \n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "\n",
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df0f474-70ee-451b-9a64-f807a7af4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifier model\n",
    "\n",
    "def build_classifier_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)\n",
    "\n",
    "classifier_model = build_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244139f4-6f6f-45e7-8af4-f9f5631f9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Epoch 1/2\n",
      "625/625 [==============================] - 115s 166ms/step - loss: 0.4442 - binary_accuracy: 0.7752 - val_loss: 0.3445 - val_binary_accuracy: 0.8482\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 102s 163ms/step - loss: 0.2817 - binary_accuracy: 0.8749 - val_loss: 0.3473 - val_binary_accuracy: 0.8580\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "epochs = 2\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)\n",
    "\n",
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds,\n",
    "                               validation_data=val_ds,\n",
    "                               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2611fe6-02e8-4437-bfd8-a746b04be6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the trained model\n",
    "\n",
    "dataset_name = 'imdb_' + bert_model_name\n",
    "saved_model_path = './{}_BERT-PubMed-GenderNeutral'.format(dataset_name.replace('/', '_'))\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298322f-baf8-4a20-b772-074bfc0c3946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
